@article{Ioannidis_2005, title={Why Most Published Research Findings Are False}, volume={2}, url={http://dx.doi.org/10.1371/journal.pmed.0020124}, DOI={10.1371/journal.pmed.0020124}, number={8}, journal={PLoS Medicine}, publisher={Public Library of Science (PLoS)}, author={Ioannidis, John P. A.}, year={2005}, month={Aug}, pages={e124}, language={en} }

@article{Ioannidis_2009, title={Repeatability of published microarray gene expression analyses}, volume={41}, url={http://dx.doi.org/10.1038/ng.295}, DOI={10.1038/ng.295}, number={2}, journal={Nature Genetics}, publisher={Springer Science and Business Media LLC}, author={Ioannidis, John P A and Allison, David B and Ball, Catherine A and Coulibaly, Issa and Cui, Xiangqin and Culhane, Aedín C and Falchi, Mario and Furlanello, Cesare and Game, Laurence and Jurman, Giuseppe and Mangion, Jon and Mehta, Tapan and Nitzberg, Michael and Page, Grier P and Petretto, Enrico and van Noort, Vera}, year={2009}, month={Jan}, pages={149–155}, language={en} }

@article{docker,
  title={Docker: lightweight linux containers for consistent development and deployment},
  author={Merkel, Dirk},
  journal={Linux journal},
  volume={2014},
  number={239},
  pages={2},
  year={2014}
}

@Article{targets,
  title = {The targets R package: a dynamic Make-like function-oriented pipeline toolkit for reproducibility and high-performance computing},
  author = {William Michael Landau},
  journal = {Journal of Open Source Software},
  year = {2021},
  volume = {6},
  number = {57},
  pages = {2959},
  url = {https://doi.org/10.21105/joss.02959},
}

@Manual{shiny,
  title = {shiny: Web Application Framework for R},
  author = {Winston Chang and Joe Cheng and JJ Allaire and Carson Sievert and Barret Schloerke and Yihui Xie and Jeff Allen and Jonathan McPherson and Alan Dipert and Barbara Borges},
  year = {2022},
  note = {R package version 1.7.2.9000},
  url = {https://shiny.rstudio.com/},
}

@Manual{R_language,
   title = {R: A Language and Environment for Statistical Computing},
     author = {{R Core Team}},
     organization = {R Foundation for Statistical Computing},
     address = {Vienna, Austria},
     year = {2022},
     url = {https://www.R-project.org/},
   }

@article{Wratten_2021, title={Reproducible, scalable, and shareable analysis pipelines with bioinformatics workflow managers}, volume={18}, url={http://dx.doi.org/10.1038/s41592-021-01254-9}, DOI={10.1038/s41592-021-01254-9}, number={10}, journal={Nature Methods}, publisher={Springer Science and Business Media LLC}, author={Wratten, Laura and Wilm, Andreas and Göke, Jonathan}, year={2021}, month={Sep}, pages={1161–1168}, language={en} }

@article{Mangul_2019, title={Improving the usability and archival stability of bioinformatics software}, volume={20}, url={http://dx.doi.org/10.1186/s13059-019-1649-8}, DOI={10.1186/s13059-019-1649-8}, number={1}, journal={Genome Biology}, publisher={Springer Science and Business Media LLC}, author={Mangul, Serghei and Martin, Lana S. and Eskin, Eleazar and Blekhman, Ran}, year={2019}, month={Feb}, language={en} }

@article{Brito_2020, title={Recommendations to enhance rigor and reproducibility in biomedical research}, volume={9}, url={http://dx.doi.org/10.1093/gigascience/giaa056}, DOI={10.1093/gigascience/giaa056}, abstractNote={<jats:title>Abstract</jats:title> <jats:p>Biomedical research depends increasingly on computational tools, but mechanisms ensuring open data, open software, and reproducibility are variably enforced by academic institutions, funders, and publishers. Publications may present software for which source code or documentation are or become unavailable; this compromises the role of peer review in evaluating technical strength and scientific contribution. Incomplete ancillary information for an academic software package may bias or limit subsequent work. We provide 8 recommendations to improve reproducibility, transparency, and rigor in computational biology—precisely the values that should be emphasized in life science curricula. Our recommendations for improving software availability, usability, and archival stability aim to foster a sustainable data science ecosystem in life science research.</jats:p>}, number={6}, journal={GigaScience}, publisher={Oxford University Press (OUP)}, author={Brito, Jaqueline J and Li, Jun and Moore, Jason H and Greene, Casey S and Nogoy, Nicole A and Garmire, Lana X and Mangul, Serghei}, year={2020}, month={Jun}, language={en} }

@article{Markowetz_2015, title={Five selfish reasons to work reproducibly}, volume={16}, url={http://dx.doi.org/10.1186/s13059-015-0850-7}, DOI={10.1186/s13059-015-0850-7}, number={1}, journal={Genome Biology}, publisher={Springer Science and Business Media LLC}, author={Markowetz, Florian}, year={2015}, month={Dec}, language={en} }

@article{Mangul_Mosqueiro_2019, title={Challenges and recommendations to improve the installability and archival stability of omics computational tools}, volume={17}, url={http://dx.doi.org/10.1371/journal.pbio.3000333}, DOI={10.1371/journal.pbio.3000333}, number={6}, journal={PLOS Biology}, publisher={Public Library of Science (PLoS)}, author={Mangul, Serghei and Mosqueiro, Thiago and Abdill, Richard J. and Duong, Dat and Mitchell, Keith and Sarwal, Varuni and Hill, Brian and Brito, Jaqueline and Littman, Russell Jared and Statz, Benjamin and Lam, Angela Ka-Mei and Dayama, Gargi and Grieneisen, Laura and Martin, Lana S. and Flint, Jonathan and Eskin, Eleazar and Blekhman, Ran}, year={2019}, month={Jun}, pages={e3000333}, language={en} }

@article{Wallach_2018, title={Reproducible research practices, transparency, and open access data in the biomedical literature, 2015–2017}, volume={16}, url={http://dx.doi.org/10.1371/journal.pbio.2006930}, DOI={10.1371/journal.pbio.2006930}, number={11}, journal={PLOS Biology}, publisher={Public Library of Science (PLoS)}, author={Wallach, Joshua D. and Boyack, Kevin W. and Ioannidis, John P. A.}, editor={Dirnagl, Ulrich}, year={2018}, month={Nov}, pages={e2006930}, language={en} }

@article{Errington_2021, title={Challenges for assessing replicability in preclinical cancer biology}, volume={10}, url={http://dx.doi.org/10.7554/eLife.67995}, DOI={10.7554/elife.67995}, abstractNote={<jats:p>We conducted the <jats:ext-link ext-link-type="uri" xlink:href="https://elifesciences.org/collections/9b1e83d1/reproducibility-project-cancer-biology">Reproducibility Project: Cancer Biology</jats:ext-link> to investigate the replicability of preclinical research in cancer biology. The initial aim of the project was to repeat 193 experiments from 53 high-impact papers, using an approach in which the experimental protocols and plans for data analysis had to be peer reviewed and accepted for publication before experimental work could begin. However, the various barriers and challenges we encountered while designing and conducting the experiments meant that we were only able to repeat 50 experiments from 23 papers. Here we report these barriers and challenges. First, many original papers failed to report key descriptive and inferential statistics: the data needed to compute effect sizes and conduct power analyses was publicly accessible for just 4 of 193 experiments. Moreover, despite contacting the authors of the original papers, we were unable to obtain these data for 68% of the experiments. Second, none of the 193 experiments were described in sufficient detail in the original paper to enable us to design protocols to repeat the experiments, so we had to seek clarifications from the original authors. While authors were <jats:italic>extremely</jats:italic> or <jats:italic>very helpful</jats:italic> for 41% of experiments, they were <jats:italic>minimally helpful</jats:italic> for 9% of experiments, and <jats:italic>not at all helpful</jats:italic> (or did not respond to us) for 32% of experiments. Third, once experimental work started, 67% of the peer-reviewed protocols required modifications to complete the research and just 41% of those modifications could be implemented. Cumulatively, these three factors limited the number of experiments that could be repeated. This experience draws attention to a basic and fundamental concern about replication – it is hard to assess whether reported findings are credible.</jats:p>}, journal={eLife}, publisher={eLife Sciences Publications, Ltd}, author={Errington, Timothy M and Denis, Alexandria and Perfito, Nicole and Iorns, Elizabeth and Nosek, Brian A}, year={2021}, month={Dec}, language={en} }

@article{Gauthier_2018, title={A brief history of bioinformatics}, volume={20}, url={http://dx.doi.org/10.1093/bib/bby063}, DOI={10.1093/bib/bby063}, abstractNote={<jats:title>Abstract</jats:title><jats:p>It is easy for today’s students and researchers to believe that modern bioinformatics emerged recently to assist next-generation sequencing data analysis. However, the very beginnings of bioinformatics occurred more than 50 years ago, when desktop computers were still a hypothesis and DNA could not yet be sequenced. The foundations of bioinformatics were laid in the early 1960s with the application of computational methods to protein sequence analysis (notably, de novo sequence assembly, biological sequence databases and substitution models). Later on, DNA analysis also emerged due to parallel advances in (i) molecular biology methods, which allowed easier manipulation of DNA, as well as its sequencing, and (ii) computer science, which saw the rise of increasingly miniaturized and more powerful computers, as well as novel software better suited to handle bioinformatics tasks. In the 1990s through the 2000s, major improvements in sequencing technology, along with reduced costs, gave rise to an exponential increase of data. The arrival of ‘Big Data’ has laid out new challenges in terms of data mining and management, calling for more expertise from computer science into the field. Coupled with an ever-increasing amount of bioinformatics tools, biological Big Data had (and continues to have) profound implications on the predictive power and reproducibility of bioinformatics results. To overcome this issue, universities are now fully integrating this discipline into the curriculum of biology students. Recent subdisciplines such as synthetic biology, systems biology and whole-cell modeling have emerged from the ever-increasing complementarity between computer science and biology.</jats:p>}, number={6}, journal={Briefings in Bioinformatics}, publisher={Oxford University Press (OUP)}, author={Gauthier, Jeff and Vincent, Antony T and Charette, Steve J and Derome, Nicolas}, year={2018}, month={Aug}, pages={1981–1996}, language={en} }

@book{Ousterhout_18,
author = {Ousterhout, John},
title = {A Philosophy of Software Design},
year = {2018},
isbn = {1732102201},
edition = {1st},
abstract = {This book addresses the topic of software design: how to decompose complex software systems into modules (such as classes and methods) that can be implemented relatively independently. The book first introduces the fundamental problem in software design, which is managing complexity. It then discusses philosophical issues about how to approach the software design process, and it presents a collection of design principles to apply during software design. The book also introduces a set of red flags that identify design problems. You can apply the ideas in this book to minimize the complexity of large software systems, so that you can write software more quickly and cheaply.}
}

@article{Ludt_2022, title={Interactive and Reproducible Workflows for Exploring and Modeling RNA‐seq Data with pcaExplorer, Ideal, and GeneTonic}, volume={2}, url={http://dx.doi.org/10.1002/cpz1.411}, DOI={10.1002/cpz1.411}, number={4}, journal={Current Protocols}, publisher={Wiley}, author={Ludt, Annekathrin and Ustjanzew, Arsenij and Binder, Harald and Strauch, Konstantin and Marini, Federico}, year={2022}, month={Apr}, language={en} }




